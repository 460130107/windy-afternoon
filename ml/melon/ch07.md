# 西瓜书概念

## 第7章 贝叶斯分类器
- Page147: 贝叶斯风险(Bayes risk)

    贝叶斯最优分类器对应的条件风险
- Page147: 贝叶斯最优分类器(Bayes optimal classifier)

    为最小化总体风险，只需在每个样本上选择那个能使条件风险最小的类别标记，此时判定准侧称为贝叶斯最优分类器。
- Page147: 风险(risk)

    决策论中将“期望损失”称为风险。
- Page147: 条件风险(conditional risk)

    基于后验概率P(ci|x)可获得将样本x分类为ci所产生的期望损失，即在样本x上的条件风险。
- Page148: 贝叶斯定理

    $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}$$

    其中， P(c)是类“先验”(prior)概率；P(x|c)是样本x相对于类标记c的类条件概率(class-conditional probability)，或称为“似然”(likelihood)；P(x)是用于归一化的“证据”(evidence)因子。估计P(c|x)的问题转化为如何基于训练数据D来估计先验P(c)和似然P(x|c)。
- Page148: 判别式模型(325)（discriminative models）

    给定x,可通过直接建模P(c|x)来预测c，这样得到的是判别式模型。

- Page148: 生成式模型(295,325)(generative models)

    先对联合概率分布P(x,c)建模，然后再由此获得P(c|x)，这样得到的是生成式模型。

- Page148: 似然(likelihood)

    见贝叶斯定理。

- Page148: 先验(Prior)

    见贝叶斯定理

- Page148: 证据（evidence）

    见贝叶斯定理

- Page149: 极大似然估计(maximum likelihood estimation， MLE)
   
   令$$D_{c}$$表示训练集D中第c类样本组成的集合，假设这些样本是独立同分布的，则参数$$\theta_{c}$$对于数据集$$D_{c}$$的似然是：
   
   $$P(D_{c}|\theta_{c}) = \prod_{x} P(x|\theta_{c})$$
   
- Page150: 朴素贝叶斯分类器(naive bayes classifier)

    基于贝叶斯公式来估计后验概率P(c|x)的主要困难在于：类条件概率P(x|c)是所有属性上的联合概率，难以从有限的训练样本直接估计而得，为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”：
    
    P(c|x) = P(c)P(x|c)/P(x)=P(c)/P(x) * Π (Pxi|c)
    
    即P(x|c)等于在c的条件下，所有属性的概率的乘积。
    
- Page150: 条件独立性假设(305)

    对已知类别，假设所有属性相互独立，换言之，假设每个属性独立的对分类结果发生影响。

- Page153: 拉普拉斯修正
- Page154: 半监督贝叶斯分类器
- Page154: 独依赖估计
- Page154: 懒惰学习(225,240)
- Page155: 超父
- Page156: 贝叶斯网(319,339)
- Page156: 概率图模型(319)
- Page156: 信念网
- Page158: V型结构
- Page158: 边际独立性
- Page158: 边际化(328)
- Page158: 道德图
- Page158: 端正图
- Page158: 同父
- Page158: 有向分离
- Page159: 最小描述长度
- Page161: 吉布斯采样(334)
- Page161: 近似推断(161)
- Page161: 精确推断(328,331)
- Page161: 马尔科夫链
- Page161: 平稳分布
- Page162: EM算法(208,295,335)
- Page162: 隐变量(319)
- Page163: 边际似然
- Page163: 坐标下降(408)
- Page164: 贝叶斯分类器
- Page164: 贝叶斯学习
